# -*- coding: utf-8 -*-
"""Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YPP5zc3dku8bpyzVaNkcU4Lg21rtGSyF

Esse codigo foi baseado no Curso introdutorio de LLM do HuggingFace
"""

!pip install datasets evaluate transformers[sentencepiece]

"""Funcao pipeline() que serão demonstradas:

1. feature-extraction (pega a representação vetorial do texto).
2. fill-mask (preenchimento de máscara).
3. ner (reconhecimento de entidades nomeadas).
4. question-answering (responder perguntas).
5. sentiment-analysis (análise de sentimentos).
6. summarization (sumarização).
7. text-generation (geração de texto).
8. translation (tradução).
9. zero-shot-classification (classificação “zero-shot”).

A maior parte dos modelos LLM são baseados no idioma inglê, porem tem opções de outros idiomas ou multilingual.

Para verificar funcoes e idiomas no HuggingFace, basta acessar a URL: https://huggingface.co/models
"""

from transformers import pipeline

sentimento = pipeline("sentiment-analysis")
sentimento("I love studying, especially LLM")

sentimento(
    ["I love studying, especially LLM", "I don't like studying a lot"]
)

from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "In these examples we will learn about LLM and AI-Ge models",
    candidate_labels=["education", "business"],
)

from transformers import pipeline

generator = pipeline("text-generation")
generator(
    "you will learn the subject of"
)  # vc vai aprender a materia de...

from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "you will learn the subject of",
    max_length=30,
    num_return_sequences=2,
)

from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("You will learn the subject of <mask> in this module.", top_k=2)

from transformers import pipeline

unmasker = pipeline("fill-mask", model="bert-base-multilingual-cased")
unmasker("Vamos aprender sobre [MASK] nesse capitulo", top_k=2)

